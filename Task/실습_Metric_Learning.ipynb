{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "실습_Metric_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjkyy2nBAM6o"
      },
      "source": [
        "#### 이 실습은 [링크](https://keras.io/examples/vision/metric_learning/)의 자료를 참고하여 구성하였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xR1qXCdTAM6v"
      },
      "source": [
        "### 필요한 라이브러리를 불러옵니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6LgG31QAM6w"
      },
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "from PIL import Image\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UnWr6rrAM6x"
      },
      "source": [
        "### 본 실기에서는 TensorFlow에서 제공하는 데이터셋 중 CIFAR-10 데이터셋을 사용합니다. \n",
        "\n",
        "### CIFAR-10은 32 x 32 크기의 6만 개의 이미지로 이루어진 데이터셋으로, 총 10개의 클래스로 분류됩니다.\n",
        "\n",
        "### 10개의 클래스는 airplane, bird, cat 등등입니다. \n",
        "\n",
        "### 데이터셋을 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru_z331mAM6x"
      },
      "source": [
        "'''데이터셋을 load 하고, train 데이터셋과 test 데이터셋으로 split 합니다.'''\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype(\"float32\") / 255.0    # normalize\n",
        "y_train = np.squeeze(y_train)\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "y_test = np.squeeze(y_test)\n",
        "\n",
        "print('학습 데이터 수 = %s\\n테스트 데이터 수 = %s' %(len(x_train), len(x_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWm-SQhBAM6y"
      },
      "source": [
        "### 샘플 데이터를 확인해봅시다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4rqc5vrAM6y"
      },
      "source": [
        "height_width = 32\n",
        "\n",
        "'''샘플 데이터를 plot 하는 함수를 정의합니다.'''\n",
        "def show_collage(examples):\n",
        "    box_size = height_width + 2\n",
        "    num_rows, num_cols = examples.shape[:2]\n",
        "\n",
        "    collage = Image.new(\n",
        "        mode=\"RGB\",\n",
        "        size=(num_cols * box_size, num_rows * box_size),\n",
        "        color=(250, 250, 250),\n",
        "    )\n",
        "    for row_idx in range(num_rows):\n",
        "        for col_idx in range(num_cols):\n",
        "            array = (np.array(examples[row_idx, col_idx]) * 255).astype(np.uint8)\n",
        "            collage.paste(\n",
        "                Image.fromarray(array), (col_idx * box_size, row_idx * box_size)\n",
        "            )\n",
        "\n",
        "    collage = collage.resize((2 * num_cols * box_size, 2 * num_rows * box_size))\n",
        "    return collage\n",
        "\n",
        "\n",
        "'''5x5 그리드로 샘플 이미지를 그립니다.'''\n",
        "sample_idxs = np.random.randint(0, 50000, size=(5, 5))\n",
        "examples = x_train[sample_idxs]\n",
        "show_collage(examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xgmjyHmAM6z"
      },
      "source": [
        "### 먼저 학습 및 테스트 데이터셋을 클래스 인덱스를 key값으로 하고 샘플 인덱스를 value값의 형태로 재배열하겠습니다. Anchor와 positive sample로 이루어진 데이터셋을 구성하는 데에 유용하게 쓸 것입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcDyCG8JAM60"
      },
      "source": [
        "class_idx_to_train_idxs = defaultdict(list)\n",
        "for y_train_idx, y in enumerate(y_train):\n",
        "    class_idx_to_train_idxs[y].append(y_train_idx)\n",
        "\n",
        "class_idx_to_test_idxs = defaultdict(list)\n",
        "for y_test_idx, y in enumerate(y_test):\n",
        "    class_idx_to_test_idxs[y].append(y_test_idx)\n",
        "    \n",
        "print('클래스 인덱스를 key값으로 가집니다: ',class_idx_to_train_idxs.keys())\n",
        "print('클래스 인덱스 0에 해당하는 샘플들의 인덱스(처음 10개)입니다: ',class_idx_to_train_idxs[0][:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gMYV8dAAM60"
      },
      "source": [
        "### 본 실습에서는 metric learning의 학습을 간단히 구현하기 위해, batch를 10개의 클래스들에 대한 anchor와 positive 쌍으로 구성합니다. \n",
        "\n",
        "### 학습의 목적은 같은 클래스에 속하는 anchor와 positive 쌍은 가깝게 embedding되도록 하고 다른 클래스에 속하는 anchor와 positive 쌍은 멀어지도록 embedding하는 것입니다.\n",
        "\n",
        "### 즉, batch를 클래스들에 대한 anchor와 positive 쌍으로 구성하여, 각각의 anchor에 대해 같은 클래스에 대응되는 positive 샘플과는 서로 가까워지도록 하고, 다른 클래스에 대응되는 positive 샘플과는 멀어지도록 합니다.\n",
        "\n",
        "### 아래에서 좀 더 자세히 설명하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "3D2sX2f8AM60"
      },
      "source": [
        "num_classes = 10    # CIFAR-10의 클래스 수는 10입니다. \n",
        "\n",
        "class AnchorPositivePairs(keras.utils.Sequence):\n",
        "    def __init__(self, num_batchs):\n",
        "        self.num_batchs = num_batchs\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_batchs\n",
        "\n",
        "    def __getitem__(self, _idx):\n",
        "        x = np.empty((2, num_classes, height_width, height_width, 3), dtype=np.float32)  # Anchor-positive 쌍으로 데이터셋을 구성하기 위해 처음 dimension이 2입니다.\n",
        "        for class_idx in range(num_classes):\n",
        "            examples_for_class = class_idx_to_train_idxs[class_idx]  # 특정 클래스 인덱스에 대한 샘플 인덱스 집합입니다.\n",
        "            anchor_idx = random.choice(examples_for_class)  # 샘플 인덱스 집합으로부터 무작위로 anchor를 위한 인덱스를 선택합니다.\n",
        "            positive_idx = random.choice(examples_for_class)  # 샘플 인덱스 집합으로부터 무작위로 positive를 위한 인덱스를 선택합니다.\n",
        "            while positive_idx == anchor_idx:  # anchor와 positive는 같은 샘플일 수 없으므로, 동일 인덱스의 경우 positive를 다시 선택합니다.\n",
        "                positive_idx = random.choice(examples_for_class)\n",
        "            x[0, class_idx] = x_train[anchor_idx]  # anchor 이미지를 특정 클래스 인덱스 값에 저장합니다.\n",
        "            x[1, class_idx] = x_train[positive_idx]  # positive 이미지를 특정 클래스 인덱스 값에 저장합니다.\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cXOikHTAM61"
      },
      "source": [
        "### 클래스들에 대해 anchor와 positive 쌍으로 이루어진 데이터셋을 구성하였습니다.\n",
        "\n",
        "### 하나의 batch에 대한 예시를 살펴보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGvUfjYhAM61"
      },
      "source": [
        "examples = next(iter(AnchorPositivePairs(num_batchs=1)))\n",
        "\n",
        "show_collage(examples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiWKitOJAM62"
      },
      "source": [
        "### 첫 번째 행은 클래스들에 대한 anchor의 이미지를, 두 번째 행은 클래스들에 대한 positive의 이미지를 나타냅니다.\n",
        "### 클래스가 위 아래로 잘 묶여 있는 것을 볼 수 있습니다. \n",
        "\n",
        "### 이제 metric learning을 위한 Embedding Model을 정의할 차례입니다. \n",
        "### 일반적인 분류(classification) 과제와 차이가 있어 커스텀 모델을 정의합니다. \n",
        "\n",
        "### 이 커스텀 모델은 anchor와 positive를 embedding한 후 그 내적 값을 softmax에 대한 logits로 사용합니다.\n",
        "### 즉, 하나의 batch는 anchor/positive 쌍 10개(클래스에 해당하는)로 이루어져 있는데, embedding vector의 dimension이 8이라고 하면, anchor에 대해 10x8의 representation 행렬을 얻고, positive에 대해서도 10x8의 representation 행렬을 얻습니다. \n",
        "\n",
        "### Anchor와 positive 두 embedding 행렬을 곱하면 10x10의 유사도 행렬을 구할 수 있는데(embedding dimension에 대한 내적이므로), 이 유사도 행렬의 첫 번째 행이 뜻하는 것은 클래스가 0인 anchor와 클래스 0~9까지의 positive들과의 유사도입니다. \n",
        "\n",
        "### 이것을 softmax의 logits라 하면, 즉 유사도 행렬의 첫 번째 행에 대응하는 sparse 라벨을 0으로 하면 해당 anchor는 클래스 0인 positive와의 유사도는 높이고 다른 클래스의 positive들과는 유사도를 낮추는 방향으로 학습됩니다. (코사인 유사도의 경우 1에 가까울수록 유사도가 높다고 판단할 수 있습니다.)\n",
        "\n",
        "### 다른 클래스에 대해서도 마찬가지로 작동합니다. anchor들은 자신과 동일한 클래스에 속하는 positive와는 가깝게 embedding되고 다른 클래스에 속하는 positive들과는 분리되도록 embedding되므로, 결과적으로 같은 클래스에 속하는 샘플들의 embedding은 가깝게 됩니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfd0Sug4AM62"
      },
      "source": [
        "class EmbeddingModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        if isinstance(data, tuple):\n",
        "            data = data[0]\n",
        "        anchors, positives = data[0], data[1]   # AnchorPositivePairs에서 0차원의 인덱스 0이 anchor, 인덱스 1이 positive였습니다. \n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # anchor와 positive를 모델에 태워 embedding vector를 계산합니다. \n",
        "            anchor_embeddings = self(anchors, training=True)\n",
        "            positive_embeddings = self(positives, training=True)\n",
        "\n",
        "            # anchor와 positive 사이의 코사인 유사도(cosine similarity)를 계산합니다. \n",
        "            # embedding 될 때 normalize되므로 코사인 유사도가 됩니다. \n",
        "            similarities = tf.einsum(\n",
        "                \"ae,pe->ap\", anchor_embeddings, positive_embeddings\n",
        "            )\n",
        "\n",
        "            # 유사도 값을 logits로 사용하므로 학습 효율성을 위해 값을 조정합니다.\n",
        "            similarities /= 0.2\n",
        "\n",
        "            sparse_labels = tf.range(num_classes) # logits에 대응하는 라벨을 만들어 줍니다. 여기서 라벨은 클래스 인덱스와 같습니다. \n",
        "            loss = self.compiled_loss(sparse_labels, similarities)\n",
        "\n",
        "        # 이하 코드는 무시하셔도 좋습니다. gradient, optimizer, metric에 관한 부분입니다. \n",
        "        gradients = tape.gradient(loss, self.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
        "        self.compiled_metrics.update_state(sparse_labels, similarities)\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIZ5FR1aAM63"
      },
      "source": [
        "### 이제 모델을 만들고 학습을 해보겠습니다. 분류 과제와는 달리 마지막 레이어에 softmax 활성화 함수를 쓰지 않으며, embedding vector까지만 만들도록 합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ30Uz8HAM64"
      },
      "source": [
        "inputs = layers.Input(shape=(height_width, height_width, 3))\n",
        "x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
        "x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "embeddings = layers.Dense(units=8, activation=None)(x)\n",
        "embeddings = tf.nn.l2_normalize(embeddings, axis=-1)\n",
        "\n",
        "model = EmbeddingModel(inputs, embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7GpxROrKAM64"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),  # EmbeddingModel에서 sparse_labels를 만들었으므로 SparseCategoricalCrossentropy loss를 씁니다. \n",
        ")\n",
        "\n",
        "history = model.fit(AnchorPositivePairs(num_batchs=1000), epochs=40)\n",
        "\n",
        "plt.plot(history.history[\"loss\"])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aKK_vcNAM64"
      },
      "source": [
        "### 학습이 잘 되고 있는 것 같습니다. \n",
        "\n",
        "### 분류 과제와 동일한 metric을 측정하려면 레이어를 추가하고 튜닝을 해야겠지만, 여기서는 테스트 데이터셋으로 간단하게 성능을 측정해보겠습니다. \n",
        "\n",
        "### 테스트 데이터셋에 대해 embedding vector를 추출 후 학습 데이터셋의 embedding vector와 유사도를 비교하여, 임의의 테스트 데이터 샘플에 대해 학습 데이터셋에서 가장 유사한 이미지가 같은 클래스에 속하는지 계산해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRsf28W1AM65"
      },
      "source": [
        "train_embed = model.predict(x_train)\n",
        "test_embed = model.predict(x_test)\n",
        "sim_mat = tf.einsum(\"ae,be->ab\", test_embed, train_embed)  # 테스트 데이터셋의 embedding vector와 학습 데이터셋의 embedding vector 사이의 유사도를 계산합니다. \n",
        "top1_test = np.argsort(sim_mat)[:,-2:]   # 학습 데이터셋에서 가장 큰 유사도를 가지는 인덱스 2개를 반환합니다. \n",
        "\n",
        "cnt = 0\n",
        "for row_idx in range(len(y_test)):\n",
        "    top1_idx = top1_test[row_idx][1]   # 1번째 인덱스가 가장 큰 유사도를 가지는 학습 데이터셋의 인덱스입니다. \n",
        "    top1_class = y_train[top1_idx]   # 해당 학습 데이터 샘플의 클래스입니다. \n",
        "    if y_test[row_idx] == top1_class:\n",
        "        cnt+=1\n",
        "print('가장 유사한 이미지를 맞춘 테스트 샘플 수: ',cnt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kAWLjG4AM65"
      },
      "source": [
        "### 결과가 썩 만족스럽지는 않지만 학습을 더 진행하면 결과가 나아질 것 같습니다. \n",
        "\n",
        "### 테스트 데이터셋의 처음 10개 샘플에 대해 가장 유사한 학습 데이터셋의 샘플이 어떻게 나왔는지 살펴보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As7181OTAM65"
      },
      "source": [
        "labels = [\n",
        "    \"Airplane\",\n",
        "    \"Automobile\",\n",
        "    \"Bird\",\n",
        "    \"Cat\",\n",
        "    \"Deer\",\n",
        "    \"Dog\",\n",
        "    \"Frog\",\n",
        "    \"Horse\",\n",
        "    \"Ship\",\n",
        "    \"Truck\",\n",
        "]\n",
        "\n",
        "rows = 10\n",
        "axes=[]\n",
        "fig=plt.figure(figsize=(4,14))\n",
        "\n",
        "for n in range(rows):\n",
        "    axes.append( fig.add_subplot(rows, 2, 2*n+1) )\n",
        "    subplot_title=(str(labels[y_test[n]]))\n",
        "    axes[-1].set_title(subplot_title)  \n",
        "    plt.imshow(x_test[n])\n",
        "    plt.axis('off')\n",
        "\n",
        "    top1_idx = top1_test[n][1]\n",
        "    axes.append( fig.add_subplot(rows, 2, 2*n+2) )\n",
        "    subplot_title=(str(labels[y_train[top1_idx]]))\n",
        "    color = \"green\" if labels[y_train[top1_idx]] == labels[y_test[n]] else \"red\"\n",
        "    axes[-1].set_title(subplot_title, color=color)     \n",
        "    plt.imshow(x_train[top1_idx])\n",
        "    plt.axis('off')\n",
        "fig.tight_layout()    \n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2TYVlH9UAM66"
      },
      "source": [
        "### 좌측 열은 테스트 데이터셋의 샘플, 우측 열은 각 샘플에 해당하는, 가장 유사도가 높은 학습 데이터셋의 샘플입니다.\n",
        "\n",
        "### 분류 과제가 아니지만 클래스별로 embedding이 된 것을 확인할 수 있습니다. \n",
        "\n",
        "### 동등한 비교는 아니지만, 동일한 모델을 분류 과제에 대해 수행하고 테스트 데이터셋에 대한 분류 정확도와 비교해보는 것은 어떨까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwHj9V3OAM66"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bplrtzjBAM67"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}