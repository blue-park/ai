{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "실습_Transfer_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzRNdp4R5nB0"
      },
      "source": [
        "#### 이 실습은 [링크](https://wiserloner.tistory.com/1049)의 자료를 참고하여 구성하였습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCZ3auAo5nB7"
      },
      "source": [
        "### 필요한 라이브러리를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "377mwnxx5nB8"
      },
      "source": [
        "!pip install tensorflow_datasets --upgrade\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Model\n",
        "tfds.disable_progress_bar()\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e21DFtLT5nB-"
      },
      "source": [
        "### 본 실기에서는 TensorFlow에서 제공하는 데이터셋 중 콩잎 데이터셋을 이용합니다.\n",
        "\n",
        "### 콩잎 데이터셋은 세 가지 상태의 콩잎을 클래스로 가지는 데이터셋입니다.\n",
        "\n",
        "### 세 가지 상태는 Angular Leaf Spot(0), Bean Rust(1), Healthy(2)로, 실기에서는 세 상태를 분류하는 이미지 task를 수행하겠습니다.\n",
        "\n",
        "### 먼저 데이터셋을 불러오겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "otlAqz6B5nB-"
      },
      "source": [
        "'''데이터셋 로드를 위해 tfds.load 를 사용합니다. 해당 데이터셋을 train과 validation으로 split합니다.'''\n",
        "(train_set, val_set, test_set), info =  tfds.load(\n",
        "    'Beans',\n",
        "    split=('train','validation', 'test'),\n",
        "    as_supervised=True, \n",
        "    with_info=True,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f02e0EA5nB_"
      },
      "source": [
        "'''데이터 포인트 개수를 확인합니다.'''\n",
        "num_train = info.splits['train'].num_examples      # 학습 데이터 수\n",
        "num_val = info.splits['validation'].num_examples   # 검증 데이터 수\n",
        "num_test = info.splits['test'].num_examples        # 테스트 데이터 수\n",
        "print('학습 데이터 수 = %s\\n검증 데이터 수 = %s\\n테스트 데이터 수 = %s' %(num_train, num_val, num_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-d05O9_W5nB_"
      },
      "source": [
        "### 데이터가 잘 받아졌는지 샘플 데이터를 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwzOyn-X5nCA"
      },
      "source": [
        "get_label_name = info.features['label'].int2str\n",
        "\n",
        "for image, label in train_set.take(3):\n",
        "    plt.figure()\n",
        "    plt.imshow(image)\n",
        "    plt.title(get_label_name(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVwabsbX5nCA"
      },
      "source": [
        "### 이미지 데이터가 normalize되어 있는지 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWSRq5LL5nCA"
      },
      "source": [
        "''' 학습 데이터셋에서 샘플 하나를 살펴봅니다.'''\n",
        "for image, label in train_set.take(1):\n",
        "    pass\n",
        "\n",
        "print('이미지 shape = %s' %(image.shape))\n",
        "print('이미지 픽셀 최대값 = %s\\n이미지 픽셀 최소값 = %s' %(tf.math.reduce_max(image), tf.math.reduce_min(image)))\n",
        "print('이미지 라벨 = %s' %(label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz5Lr-WU5nCB"
      },
      "source": [
        "### 라벨값은 0,1,2 세 값을 가집니다. \n",
        "\n",
        "### 픽셀 값이 0~255의 범위이므로 normalize 함수를 정의합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NREl-puj5nCB"
      },
      "source": [
        "'''전처리 함수를 정의합니다.'''\n",
        "def convert(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = image/255.0\n",
        "    # image = tf.image.resize(image, (500,500))   # 필요하다면 모델 입력 shape에 맞게 resize를 진행할 수 있습니다. \n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8QLIKpY5nCB"
      },
      "source": [
        "### 데이터셋 객체를 이용해 학습 데이터를 준비해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyS4pOW35nCC"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_batches = (\n",
        "    train_set\n",
        "    .shuffle(num_train)\n",
        "    .map(convert, num_parallel_calls=AUTOTUNE)  # map을 통해 위에서 정의한 전처리 함수를 콜백함수로 적용시킵니다.\n",
        "    .batch(BATCH_SIZE)  # 배치 사이즈를 설정합니다. \n",
        "    .prefetch(AUTOTUNE)\n",
        ") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeAN5LZu5nCC"
      },
      "source": [
        "### 같은 방식으로 검증 데이터와 테스트 데이터를 준비합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_363iIC5nCD"
      },
      "source": [
        "val_batches = (\n",
        "    val_set\n",
        "    .map(convert, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        ")\n",
        "\n",
        "test_batches = (\n",
        "    test_set\n",
        "    .map(convert, num_parallel_calls=AUTOTUNE)\n",
        "    .batch(BATCH_SIZE)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcEjCCmh5nCD"
      },
      "source": [
        "### 이제 ImageNet 데이터로 사전학습된 VGG16 모델을 이용해 task에 맞게 레이어를 추가해보겠습니다. \n",
        "\n",
        "### 모델 로드 시 include_top을 False로 지정하면 Flatten 레이어와 FC Classifier 블록을 제외하고 받을 수 있습니다.\n",
        "\n",
        "### 모델을 로드하고 Flatten 레이어까지 추가합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3sTG2Z25nCD"
      },
      "source": [
        "IMG_SHAPE = (500,500,3)\n",
        "\n",
        "'''사전 훈련된 VGG16 모델로부터 기본 모델을 만듭니다.'''\n",
        "vgg_pre = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                      include_top=False,\n",
        "                                      weights='imagenet')    # ImageNet pre-trained weights를 로드합니다. \n",
        "# vgg_pre 모델의 구조를 vgg_pre.summary()로 확인하고 강의 자료의 그림과 비교해보세요.\n",
        "'''Flatten 레이어를 추가합니다.'''\n",
        "output = vgg_pre.layers[-1].output\n",
        "output = tf.keras.layers.Flatten()(output)\n",
        "vgg1 = Model(vgg_pre.input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zblu-NSH5nCE"
      },
      "source": [
        "### 위에서 정의한 vgg1 모델을 Feature Extractor로 사용할 것이므로, Feature Extractor 부분을 freeze하고 결과를 확인합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-G_CcOM5nCE"
      },
      "source": [
        "vgg1.trainable = False\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg1.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqG1Dllo5nCE"
      },
      "source": [
        "### 모든 레이어가 잘 freeze된 것을 볼 수 있습니다. \n",
        "### 이제 vgg1 모델에 fully-connected layer를 추가하여 모델이 세 개의 상태를 분류할 수 있게 만들어 줍시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNMTMPLc5nCE"
      },
      "source": [
        "tf.random.set_seed(2021)\n",
        "model1 = Sequential()\n",
        "model1.add(vgg1)\n",
        "model1.add(Dense(128, activation='relu'))\n",
        "model1.add(Dense(128, activation='relu'))\n",
        "model1.add(Dense(3))    # 세 개의 상태를 분류하는 task입니다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkOf8Rqf5nCF"
      },
      "source": [
        "### 모델이 잘 작동할지 학습해 보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y_-RooI5nCF"
      },
      "source": [
        "model1.compile(optimizer = optimizers.Adagrad(learning_rate=0.001),\n",
        "               loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "               metrics='accuracy')\n",
        "history = model1.fit(train_batches, epochs=5, validation_data=val_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InWKOToO5nCF"
      },
      "source": [
        "### 5 epoch을 학습한 결과로는 꽤 괜찮은 것 같습니다. 우리는 그저 누군가가 미리 학습해 놓은 결과를 가지고 와서 간단한 모델을 만들었을 뿐입니다. \n",
        "\n",
        "### 하지만 사전학습된 weights를 사용하지 않고 random하게 초기화된 값에서 모델 학습을 시작한다면 어떨까요? \n",
        "\n",
        "### 사전학습된 weights가 정말로 효과가 있는지 확인해 봅시다.\n",
        "### 동일한 모델이지만 weights만 다른 VGG16 모델을 로드합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "HiMW_Ec15nCF"
      },
      "source": [
        "vgg_random = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                         include_top=False,\n",
        "                                         weights=None)     # random하게 초기화된 값으로 로드합니다. \n",
        "output = vgg_random.layers[-1].output\n",
        "output = tf.keras.layers.Flatten()(output)\n",
        "vgg2 = Model(vgg_random.input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1EgDEP05nCG"
      },
      "source": [
        "### Random하게 초기화된 weights이므로 weights를 freeze하면 안될 것입니다. 레이어 weights가 업데이트되는 상태인지 확인해 봅시다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMzMuyrg5nCH"
      },
      "source": [
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg2.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_A5U2Qt5nCH"
      },
      "source": [
        "### 좋습니다. 이제 위와 동일한 방법으로 모델을 만들어 학습해 보겠습니다. \n",
        "\n",
        "### (학습이 10분 정도 걸립니다... 학습 시작 후 잠시 휴식하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqOydqH-5nCH"
      },
      "source": [
        "tf.random.set_seed(2021)\n",
        "model2 = Sequential()\n",
        "model2.add(vgg2)\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(128, activation='relu'))\n",
        "model2.add(Dense(3))\n",
        "\n",
        "model2.compile(optimizer = optimizers.Adagrad(learning_rate=0.001),    # learning rate을 조금 높였습니다. \n",
        "               loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "               metrics='accuracy')\n",
        "aug_history = model2.fit(train_batches, epochs=5, validation_data=val_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMvguDDV5nCI"
      },
      "source": [
        "### 사전학습된 weights의 효과는 명백해 보입니다! Random한 값으로 초기화된 모델로 바닥에서부터 학습하면 학습 시간도 오래 걸리고 정확도도 높지 않습니다. \n",
        "\n",
        "### 사전학습된 weights로 학습을 시작하면, 유용한 feature를 가지고 시작하므로 높은 정확도로 빠르게 수렴합니다. \n",
        "\n",
        "### 하지만 사전학습된 weights, 즉 ImageNet으로 학습된 feature는 해당 task에 좀 더 적합할 것이고, 콩잎의 상태를 분류하기 위해서는 학습된 feature를 수정해도 좋을 것 같습니다. \n",
        "\n",
        "### VGG16 모델의 block5를 fine-tuning하고 결과를 비교해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRrd1lBb5nCI"
      },
      "source": [
        "'''ImageNet 사전학습된 weights를 불러옵니다.'''\n",
        "vgg_pre = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                      include_top=False,\n",
        "                                      weights='imagenet')\n",
        "output = vgg_pre.layers[-1].output\n",
        "output = tf.keras.layers.Flatten()(output)\n",
        "vgg3 = Model(vgg_pre.input, output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzrlSOdR5nCI"
      },
      "source": [
        "### VGG16 모델의 Layer Name을 block1부터 block5까지 순서대로이므로, block5_conv1 레이어부터 freeze를 풀겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zdjQOen5nCJ"
      },
      "source": [
        "vgg3.trainable = False\n",
        "\n",
        "set_trainable = False\n",
        "for layer in vgg3.layers:\n",
        "    if layer.name in ['block5_conv1']:\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "\n",
        "layers = [(layer, layer.name, layer.trainable) for layer in vgg3.layers]\n",
        "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOIGMiM05nCJ"
      },
      "source": [
        "### 이제 동일한 방법으로 학습을 진행해보겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xIefdd_5nCJ"
      },
      "source": [
        "tf.random.set_seed(2021)\n",
        "model3 = Sequential()\n",
        "model3.add(vgg3)\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dense(128, activation='relu'))\n",
        "model3.add(Dense(3))\n",
        "\n",
        "model3.compile(optimizer = optimizers.Adagrad(learning_rate=0.001),\n",
        "               loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "               metrics='accuracy')\n",
        "aug_history = model3.fit(train_batches, epochs=5, validation_data=val_batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5LKFt4M5nCJ"
      },
      "source": [
        "### 정확도에 개선이 있는 것을 확인할 수 있습니다.  \n",
        "\n",
        "### 적절하게 fine-tuning을 이용하면 현재 task에 더욱 적합한 feature를 배우는 데에 도움을 줄 수 있습니다. \n",
        "\n",
        "### Fine-tuning을 거친 모델을 통해 test 이미지를 추론해보고 결과를 시각화하겠습니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PncD5AHi5nCJ"
      },
      "source": [
        "# 새로운 모델로 추론\n",
        "pred_batch = model3.predict(test_batches)\n",
        "pred_label = np.argmax(pred_batch, axis=-1)\n",
        "\n",
        "# 실제 라벨 (Ground Truth)\n",
        "temp_test = tfds.as_numpy(test_set)\n",
        "true_img = np.array([x[0] for x in temp_test])\n",
        "true_label = np.array([x[1] for x in temp_test])\n",
        "\n",
        "plt.figure(figsize=(20,16))\n",
        "plt.subplots_adjust(hspace=0.3)\n",
        "for n in range(20):\n",
        "    plt.subplot(5,4,n+1)\n",
        "    plt.imshow(true_img[n])\n",
        "    color = \"green\" if pred_label[n] == true_label[n] else \"red\"\n",
        "    plt.title(get_label_name(pred_label[n]).title(), color=color)\n",
        "    plt.axis('off')\n",
        "_ = plt.suptitle(\"Model predictions (green: correct, red: incorrect)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YonzXzoQ5nCK"
      },
      "source": [
        "### 초록색 표시는 모델이 맞춘 정답, 붉은색 표시는 모델이 틀린 경우입니다.\n",
        "\n",
        "### 테스트 데이터에 대해 결과가 괜찮게 나온 것 같습니다. "
      ]
    }
  ]
}