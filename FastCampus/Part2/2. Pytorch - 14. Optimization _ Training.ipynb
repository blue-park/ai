{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: Optimization & Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/pytorch/examples/tree/master/mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "\n",
    "batch_size = 64\n",
    "test_batch_size = 64\n",
    "\n",
    "no_cuda = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = not no_cuda and torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('dataset', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('dataset', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=test_batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 20, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model과 Optimization 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습하기 전에 Model이 Train할 수 있도록 Train Mode로 변환\n",
    "    - Convolution 또는 Linear 뿐만 아니라, DropOut과 추후에 배우게 될 Batch Normalization과 같이 parameter를 가진 Layer들도 학습하기 위해 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 5, 5])\n",
      "torch.Size([20])\n",
      "torch.Size([50, 20, 5, 5])\n",
      "torch.Size([50])\n",
      "torch.Size([500, 800])\n",
      "torch.Size([500])\n",
      "torch.Size([10, 500])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "params = list(model.parameters())\n",
    "for i in range(8):\n",
    "    print(params[i].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train() # train mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델에 넣기 위한 첫 Batch 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 추출한 Batch 데이터를 cpu 또는 gpu와 같은 device에 compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = data.to(device), target.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 1, 28, 28]), torch.Size([64]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gradients를 clear해서 새로운 최적화 값을 찾기 위해 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 준비한 데이터를 model에 input으로 넣어 output을 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Model에서 예측한 결과를 Loss Function에 넣음\n",
    "    - 여기 예제에서는 Negative Log-Likelihood Loss 라는 Loss Function을 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.nll_loss(output, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Back Propagation을 통해 Gradients를 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 계산된 Gradients는 계산된 걸로 끝이 아니라 Parameter에 Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 최적화 과정을 반복하여 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 0%]\tLoss: 0.350869\n",
      "Train Epoch: 1 [6400/60000 11%]\tLoss: 0.430692\n",
      "Train Epoch: 1 [12800/60000 21%]\tLoss: 0.293032\n",
      "Train Epoch: 1 [19200/60000 32%]\tLoss: 0.303908\n",
      "Train Epoch: 1 [25600/60000 43%]\tLoss: 0.271252\n",
      "Train Epoch: 1 [32000/60000 53%]\tLoss: 0.221334\n",
      "Train Epoch: 1 [38400/60000 64%]\tLoss: 0.406929\n",
      "Train Epoch: 1 [44800/60000 75%]\tLoss: 0.160506\n",
      "Train Epoch: 1 [51200/60000 85%]\tLoss: 0.291229\n",
      "Train Epoch: 1 [57600/60000 96%]\tLoss: 0.137454\n",
      "Training end...\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "    #train mode\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} {:,.0f}%]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100 * batch_idx / len(train_loader), loss.item()\n",
    "            ))\n",
    "    print('Training end...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 앞에서 model.train() 모드로 변한 것처럼 평가 할 때는 model.eval()로 설정\n",
    "    - Batch Normalization이나 Drop Out 같은 Layer들을 잠금"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=800, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- autograd engine, 즉 backpropagatin이나 gradient 계산 등을 꺼서 memory usage를 줄이고 속도를 높임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    data,target = next(iter(test_loader))\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "    \n",
    "    test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "    \n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    correct = pred.eq(target.view_as(pred)).sum().item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [9],\n",
       "        [8],\n",
       "        [6],\n",
       "        [4],\n",
       "        [0],\n",
       "        [9],\n",
       "        [6],\n",
       "        [7],\n",
       "        [3],\n",
       "        [2],\n",
       "        [2],\n",
       "        [5],\n",
       "        [5],\n",
       "        [8],\n",
       "        [5],\n",
       "        [1],\n",
       "        [5],\n",
       "        [8],\n",
       "        [7],\n",
       "        [1],\n",
       "        [8],\n",
       "        [7],\n",
       "        [5],\n",
       "        [4],\n",
       "        [7],\n",
       "        [3],\n",
       "        [5],\n",
       "        [1],\n",
       "        [8],\n",
       "        [1],\n",
       "        [3],\n",
       "        [9],\n",
       "        [7],\n",
       "        [1],\n",
       "        [8],\n",
       "        [1],\n",
       "        [7],\n",
       "        [8],\n",
       "        [0],\n",
       "        [6],\n",
       "        [4],\n",
       "        [2],\n",
       "        [4],\n",
       "        [2],\n",
       "        [1],\n",
       "        [2],\n",
       "        [9],\n",
       "        [2],\n",
       "        [6],\n",
       "        [2],\n",
       "        [5],\n",
       "        [8],\n",
       "        [7],\n",
       "        [0],\n",
       "        [3],\n",
       "        [8],\n",
       "        [1],\n",
       "        [3],\n",
       "        [1],\n",
       "        [3],\n",
       "        [7],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.505084991455078"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.0254e+01, -9.0420e-03, -6.5606e+00, -7.5774e+00, -9.3938e+00,\n",
       "         -7.2770e+00, -6.1380e+00, -7.5841e+00, -5.6661e+00, -8.9072e+00],\n",
       "        [-8.5098e+00, -1.1728e+01, -7.2284e+00, -8.3469e+00, -2.4412e+00,\n",
       "         -9.1402e+00, -8.8956e+00, -3.5018e+00, -7.2390e+00, -1.2708e-01],\n",
       "        [-1.0711e+01, -1.0626e+01, -8.9055e+00, -7.2756e+00, -8.2785e+00,\n",
       "         -4.7414e+00, -8.3619e+00, -1.0530e+01, -1.1049e-02, -7.0436e+00],\n",
       "        [-8.6246e+00, -1.6167e+01, -5.8755e+00, -1.4810e+01, -7.6304e+00,\n",
       "         -7.4065e+00, -4.3654e-03, -1.6412e+01, -8.3640e+00, -1.0071e+01],\n",
       "        [-1.1966e+01, -1.9061e+01, -1.0615e+01, -1.4001e+01, -9.9633e-04,\n",
       "         -1.0583e+01, -7.5012e+00, -1.3297e+01, -8.7832e+00, -8.3718e+00],\n",
       "        [-2.5558e-02, -1.3615e+01, -4.8333e+00, -7.6530e+00, -1.0996e+01,\n",
       "         -5.2406e+00, -5.0184e+00, -8.9264e+00, -5.5138e+00, -7.2574e+00],\n",
       "        [-5.6799e+00, -1.1548e+01, -8.2430e+00, -1.0253e+01, -1.8347e+00,\n",
       "         -6.4526e+00, -9.1644e+00, -2.6399e+00, -4.3606e+00, -2.8663e-01],\n",
       "        [-5.8702e+00, -1.2173e+01, -3.0017e+00, -7.3136e+00, -1.8233e+00,\n",
       "         -7.0490e+00, -2.5488e-01, -5.1019e+00, -6.3499e+00, -6.4354e+00],\n",
       "        [-1.0954e+01, -1.3738e+01, -1.2789e+01, -6.9088e+00, -1.0289e+01,\n",
       "         -1.0069e+01, -1.5737e+01, -5.6447e-03, -1.1681e+01, -5.3985e+00],\n",
       "        [-1.2811e+01, -1.0584e+01, -8.9989e+00, -2.5120e-01, -1.3295e+01,\n",
       "         -1.5200e+00, -1.1781e+01, -1.0662e+01, -5.8963e+00, -7.6083e+00],\n",
       "        [-7.9442e+00, -4.2437e+00, -4.1617e-01, -2.5931e+00, -8.3580e+00,\n",
       "         -6.0422e+00, -6.9424e+00, -1.7223e+00, -3.0904e+00, -3.7628e+00],\n",
       "        [-1.7050e+01, -1.0385e+01, -3.8203e-03, -5.8083e+00, -2.1755e+01,\n",
       "         -1.3238e+01, -1.1290e+01, -1.3099e+01, -7.1780e+00, -1.7111e+01],\n",
       "        [-1.1487e+01, -1.5917e+01, -9.0715e+00, -6.7052e+00, -1.4309e+01,\n",
       "         -4.3832e-03, -9.1878e+00, -1.6116e+01, -5.8386e+00, -1.1752e+01],\n",
       "        [-6.5405e+00, -1.1370e+01, -9.2472e+00, -3.9154e+00, -5.0353e+00,\n",
       "         -1.3973e-01, -6.3978e+00, -6.7990e+00, -5.3345e+00, -2.3558e+00],\n",
       "        [-7.3791e+00, -8.2894e+00, -4.2188e+00, -7.8212e+00, -9.0026e+00,\n",
       "         -4.9544e+00, -4.5909e+00, -1.1393e+01, -3.4070e-02, -8.6673e+00],\n",
       "        [-8.7592e+00, -1.2664e+01, -1.1942e+01, -9.8529e+00, -7.3874e+00,\n",
       "         -1.5062e-02, -1.0032e+01, -9.5919e+00, -5.0545e+00, -4.8773e+00],\n",
       "        [-1.5060e+01, -4.2216e-03, -7.6966e+00, -6.6210e+00, -9.1631e+00,\n",
       "         -9.4415e+00, -9.7682e+00, -7.0091e+00, -7.3209e+00, -7.3867e+00],\n",
       "        [-8.0781e+00, -1.0621e+01, -1.0570e+01, -7.9503e+00, -6.7037e+00,\n",
       "         -1.7375e-02, -1.0073e+01, -7.9504e+00, -4.8412e+00, -4.9628e+00],\n",
       "        [-9.5514e+00, -1.7532e+01, -4.7081e+00, -7.1992e+00, -1.5049e+01,\n",
       "         -6.5398e+00, -1.1696e+01, -1.5412e+01, -1.1377e-02, -1.0843e+01],\n",
       "        [-1.1377e+01, -1.7128e+01, -1.4198e+01, -1.1015e+01, -1.2998e+01,\n",
       "         -1.1730e+01, -1.9044e+01, -2.1182e-03, -1.3175e+01, -6.1777e+00],\n",
       "        [-1.1013e+01, -1.0366e-02, -6.1091e+00, -6.9641e+00, -8.3551e+00,\n",
       "         -9.4653e+00, -9.1890e+00, -6.4659e+00, -5.2882e+00, -9.1474e+00],\n",
       "        [-6.3940e+00, -1.7781e+01, -4.9552e+00, -1.1017e+01, -1.1751e+01,\n",
       "         -6.3768e+00, -9.5492e+00, -1.0654e+01, -1.4073e-02, -5.6732e+00],\n",
       "        [-1.5495e+01, -1.8796e+01, -1.6662e+01, -1.2647e+01, -1.5341e+01,\n",
       "         -1.4597e+01, -2.4531e+01, -2.5406e-03, -1.3741e+01, -5.9787e+00],\n",
       "        [-1.0962e+01, -7.0772e+00, -7.9787e+00, -1.7089e+00, -5.0570e+00,\n",
       "         -2.6266e-01, -6.5412e+00, -8.0821e+00, -4.2491e+00, -3.6369e+00],\n",
       "        [-1.6270e+01, -9.8709e+00, -1.2013e+01, -1.0229e+01, -1.0232e-01,\n",
       "         -7.6533e+00, -9.6837e+00, -4.8513e+00, -3.8703e+00, -2.6889e+00],\n",
       "        [-1.1696e+01, -1.6314e+01, -1.5937e+01, -1.1249e+01, -7.3389e+00,\n",
       "         -1.0154e+01, -1.8358e+01, -1.9843e-01, -1.1227e+01, -1.7189e+00],\n",
       "        [-1.2367e+01, -7.8978e+00, -6.2878e+00, -1.0416e-02, -1.5399e+01,\n",
       "         -7.8182e+00, -1.8598e+01, -5.9331e+00, -5.8011e+00, -6.1899e+00],\n",
       "        [-8.5405e+00, -1.3769e+01, -1.1454e+01, -9.9784e+00, -3.1901e+00,\n",
       "         -5.6717e-02, -4.7291e+00, -1.3671e+01, -5.3858e+00, -8.1110e+00],\n",
       "        [-1.1485e+01, -8.1219e-03, -7.0146e+00, -5.9862e+00, -9.2250e+00,\n",
       "         -7.6521e+00, -7.9790e+00, -6.7912e+00, -6.2299e+00, -7.3272e+00],\n",
       "        [-1.2914e+01, -1.0268e+01, -4.3921e+00, -7.2296e+00, -1.0694e+01,\n",
       "         -6.9767e+00, -8.2389e+00, -1.3407e+01, -1.4508e-02, -1.0015e+01],\n",
       "        [-1.4356e+01, -4.1321e-03, -7.6189e+00, -7.3850e+00, -8.4569e+00,\n",
       "         -8.2235e+00, -7.6942e+00, -8.3206e+00, -6.4648e+00, -8.2013e+00],\n",
       "        [-6.9743e+00, -1.3677e+01, -7.0152e+00, -4.8636e-03, -1.6174e+01,\n",
       "         -6.0985e+00, -1.2074e+01, -1.1422e+01, -7.2102e+00, -1.1113e+01],\n",
       "        [-1.2172e+01, -9.8330e+00, -1.0532e+01, -1.0106e+01, -1.3276e+00,\n",
       "         -6.0331e+00, -8.8118e+00, -6.2043e+00, -5.7825e+00, -3.1867e-01],\n",
       "        [-1.5006e+01, -2.0505e+01, -1.5368e+01, -1.2709e+01, -1.5414e+01,\n",
       "         -1.5843e+01, -2.2694e+01, -2.4102e-03, -1.5080e+01, -6.0310e+00],\n",
       "        [-1.0870e+01, -3.5496e-02, -6.7577e+00, -5.1250e+00, -7.2221e+00,\n",
       "         -7.5882e+00, -8.3840e+00, -3.8846e+00, -6.4231e+00, -5.4963e+00],\n",
       "        [-1.1309e+01, -8.4218e+00, -4.6004e+00, -4.0409e+00, -7.7548e+00,\n",
       "         -5.9335e+00, -6.9619e+00, -9.8922e+00, -3.4601e-02, -6.1791e+00],\n",
       "        [-8.8815e+00, -3.0763e-02, -4.7207e+00, -5.5680e+00, -8.3554e+00,\n",
       "         -9.4893e+00, -9.6135e+00, -4.5482e+00, -5.1132e+00, -7.7109e+00],\n",
       "        [-9.8687e+00, -6.8975e+00, -3.1375e+00, -4.8260e+00, -1.0986e+01,\n",
       "         -1.0042e+01, -1.4590e+01, -7.4437e-02, -5.1263e+00, -4.3227e+00],\n",
       "        [-9.4724e+00, -7.3375e+00, -8.0583e+00, -3.6299e+00, -2.4288e+00,\n",
       "         -3.1552e+00, -6.9747e+00, -2.2303e+00, -3.7938e-01, -3.0169e+00],\n",
       "        [-1.0086e-03, -2.0391e+01, -8.6776e+00, -1.2831e+01, -1.4712e+01,\n",
       "         -8.0092e+00, -8.8719e+00, -1.3408e+01, -7.9989e+00, -1.0608e+01],\n",
       "        [-8.7344e+00, -1.6422e+01, -4.5547e+00, -1.3972e+01, -9.7081e+00,\n",
       "         -9.4694e+00, -1.1361e-02, -1.5440e+01, -7.6566e+00, -1.2126e+01],\n",
       "        [-1.1744e+01, -8.7073e+00, -8.8594e+00, -1.1073e+01, -1.6766e-02,\n",
       "         -7.3861e+00, -6.9572e+00, -7.9762e+00, -5.8340e+00, -4.4694e+00],\n",
       "        [-7.2033e+00, -1.0583e+01, -9.1546e-02, -2.6077e+00, -6.8497e+00,\n",
       "         -8.7467e+00, -8.2857e+00, -8.2941e+00, -5.3184e+00, -5.0538e+00],\n",
       "        [-1.5582e+01, -9.9656e+00, -1.1855e+01, -6.8584e+00, -1.1492e-01,\n",
       "         -8.6566e+00, -1.0880e+01, -6.8010e+00, -7.3308e+00, -2.2491e+00],\n",
       "        [-4.9476e+00, -6.6477e+00, -8.6883e-01, -6.5681e+00, -2.1443e+00,\n",
       "         -3.6064e+00, -8.7337e-01, -7.4222e+00, -5.2662e+00, -5.7594e+00],\n",
       "        [-1.3287e+01, -3.3367e-03, -7.8857e+00, -7.8948e+00, -9.6042e+00,\n",
       "         -1.0395e+01, -9.6208e+00, -6.4350e+00, -7.3417e+00, -8.7161e+00],\n",
       "        [-1.2388e+01, -9.8148e+00, -1.5736e-03, -7.5728e+00, -1.4115e+01,\n",
       "         -1.4210e+01, -1.2315e+01, -8.2724e+00, -7.3913e+00, -9.0166e+00],\n",
       "        [-1.4146e+01, -1.2724e+01, -1.0203e+01, -4.8658e+00, -2.5667e+00,\n",
       "         -5.5782e+00, -1.1234e+01, -6.2116e+00, -5.2589e+00, -1.0041e-01],\n",
       "        [-7.8566e+00, -1.1963e+01, -1.0269e-01, -2.3570e+00, -1.3893e+01,\n",
       "         -9.6153e+00, -9.5800e+00, -6.4268e+00, -7.3590e+00, -9.1528e+00],\n",
       "        [-1.1887e+01, -1.5936e+01, -6.4027e+00, -1.5651e+01, -4.1872e+00,\n",
       "         -1.1791e+01, -1.7087e-02, -1.3835e+01, -9.9879e+00, -1.0276e+01],\n",
       "        [-7.3893e+00, -7.4355e+00, -3.9396e-01, -3.9587e+00, -1.5535e+01,\n",
       "         -8.5527e+00, -1.0688e+01, -1.0699e+01, -1.1872e+00, -1.0691e+01],\n",
       "        [-7.9560e+00, -6.0376e+00, -7.4550e+00, -7.4315e+00, -6.6918e+00,\n",
       "         -3.2049e-02, -6.7984e+00, -7.4493e+00, -3.7521e+00, -6.7052e+00],\n",
       "        [-7.4862e+00, -1.3370e+01, -6.0591e+00, -1.0656e+01, -8.3239e+00,\n",
       "         -3.7503e+00, -7.2802e+00, -1.3598e+01, -2.8619e-02, -7.0726e+00],\n",
       "        [-9.7087e+00, -9.4177e+00, -1.1204e+00, -5.2900e+00, -1.0789e+01,\n",
       "         -1.1908e+01, -1.3691e+01, -4.2342e-01, -7.4726e+00, -4.3219e+00],\n",
       "        [-8.0827e-04, -1.7857e+01, -1.0008e+01, -9.0599e+00, -1.4926e+01,\n",
       "         -7.5783e+00, -9.4891e+00, -1.1812e+01, -1.0165e+01, -1.1217e+01],\n",
       "        [-1.0973e+01, -7.1573e+00, -5.2902e+00, -4.3527e-02, -8.5131e+00,\n",
       "         -5.1913e+00, -1.1415e+01, -8.5797e+00, -3.6487e+00, -5.3460e+00],\n",
       "        [-8.1623e+00, -8.7536e+00, -6.3160e+00, -4.1739e+00, -9.5952e+00,\n",
       "         -4.2275e+00, -8.9631e+00, -1.0097e+01, -3.5676e-02, -5.9603e+00],\n",
       "        [-1.1767e+01, -1.8178e-02, -6.6495e+00, -6.8206e+00, -9.3609e+00,\n",
       "         -6.0314e+00, -6.4317e+00, -8.3940e+00, -4.5105e+00, -8.1013e+00],\n",
       "        [-7.5752e+00, -7.4863e+00, -4.1242e+00, -1.2563e-01, -7.7709e+00,\n",
       "         -2.7035e+00, -5.4597e+00, -3.6201e+00, -6.6285e+00, -6.8494e+00],\n",
       "        [-1.0567e+01, -2.4939e-02, -6.1714e+00, -5.2030e+00, -8.3070e+00,\n",
       "         -7.5964e+00, -8.2525e+00, -4.6554e+00, -5.7581e+00, -5.7019e+00],\n",
       "        [-7.8370e+00, -1.2536e+01, -8.4824e+00, -1.0701e-01, -1.7150e+01,\n",
       "         -2.3118e+00, -1.3013e+01, -1.3057e+01, -6.3488e+00, -1.0076e+01],\n",
       "        [-1.5150e+01, -1.7134e+01, -1.5434e+01, -1.1772e+01, -1.2496e+01,\n",
       "         -1.3900e+01, -2.2009e+01, -6.5312e-03, -1.3172e+01, -5.0367e+00],\n",
       "        [-5.7586e+00, -1.6189e-01, -3.7171e+00, -5.7501e+00, -5.6320e+00,\n",
       "         -4.2780e+00, -2.6926e+00, -6.2608e+00, -3.4692e+00, -7.3982e+00],\n",
       "        [-1.3122e+01, -5.7368e-03, -7.8228e+00, -8.7640e+00, -9.5728e+00,\n",
       "         -8.6160e+00, -7.9371e+00, -8.1506e+00, -5.4966e+00, -8.7144e+00]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 9, 8, 6, 4, 0, 9, 6, 7, 3, 2, 2, 5, 5, 8, 5, 1, 5, 8, 7, 1, 8, 7, 5,\n",
       "        4, 7, 3, 5, 1, 8, 1, 3, 9, 7, 1, 8, 1, 7, 8, 0, 6, 4, 2, 4, 2, 1, 2, 9,\n",
       "        2, 6, 2, 5, 8, 7, 0, 3, 8, 1, 5, 1, 3, 7, 1, 1])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984375"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.eq(target.view_as(pred)).sum().item()/64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.505084991455078"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss /= len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0008505084991455078"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average Loss: 0.2251, Accuracy: 9335/10000 (93%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        output = model(data)\n",
    "        test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "test_loss /= len(test_loader.dataset)\n",
    "\n",
    "print('\\nTest set: Average Loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset), 100 * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
